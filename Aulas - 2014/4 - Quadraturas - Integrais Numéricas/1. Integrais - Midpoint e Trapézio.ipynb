{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plano de hoje\n",
    "-------------\n",
    "\n",
    "1. Ambiente de programação\n",
    "2. Usando o computador para calcular    \n",
    "3. Usando o computador para desenhar\n",
    "4. Usando o computador para integrar: quadraturas\n",
    "    1. Primeiras aproximações: Fórmula do ponto médio e dos trapézios (Seções 4.3.1 e 4.3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrais\n",
    "\n",
    "A derivada de uma função (conhecida \"explicitamente\") sempre pode ser obtida aplicando-se as diversas regras de derivação.\n",
    "Assim, até um computador pode calcular _algebricamente_ a derivada de expressões explícitas **arbitrariamente complexas**.\n",
    "Como $f(x) = \\exp(x^3 - \\log(x)) + \\frac{\\sin(\\tan(1-x))}{\\cos(\\cos(x) - e) + 1}$.\n",
    "\n",
    "Mas para integrais não é tão simples obter expressões analíticas explícitas.\n",
    "De fato, desde [um teorema de Liouville de 1835][1],\n",
    "sabemos que existem funções cuja integral não pode ser expressa em \"termos simples\".\n",
    "Como por exemplo $f(x) = \\exp(-x^2)$, portanto bastante \"simples\" em sua expressão.\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Liouville%27s_theorem_(differential_algebra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, possuir métodos para calcular derivadas numericamente é ainda mais importante.\n",
    "E, felizmente, há diversos métodos, com bastante precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrais = somas de Riemann\n",
    "\n",
    "Vamos, aqui, nos concentrar no caso mais simples, mas também mais importante,\n",
    "do cálculo de uma integral _definida_ de uma função contínua: $$\\int_a^b f(x) \\, dx. $$\n",
    "\n",
    "Uma tal integral é o limite das _somas de Riemann_: $\\int f = \\lim_{n\\to\\infty} S_n$, onde\n",
    "$$S_n = \\sum_{k = 0}^{n-1} f(x_k) \\cdot h$$\n",
    "onde $x_k$ será um ponto do intervalo [x + kh, x + kh + h],\n",
    "e $h = \\frac{b-a}{n}$ é o tamanho de cada intervalo da partição.\n",
    "\n",
    "Assim como fizemos para a derivada, onde \"paramos\" o limite antes de obter $h = 0$,\n",
    "vamos também, para a integral, calcular apenas $S_n$ para um $n$ suficientemente grande.\n",
    "E, também como fizemos para a derivada, vamos usar $h$ como variável principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uma fórmula de Cauchy\n",
    "\n",
    "Resta, apenas, dar um critério para escolher os $x_k$.\n",
    "O primeiro (historicamente) é tomar $x_k = a + kh$, e é (às vezes) descrito como \"soma de Cauchy\".\n",
    "(Riemann mostrou que não precisávamos de _nenhuma_ regra para os $x_k$:\n",
    "conquanto os intervalos diminuíssem e a função fosse contínua,\n",
    "as somas $S_n$ convergiriam para a sua integral.\n",
    "Mas isso não nos interessa aqui: **precisamos** dar uma regra para o computador!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício:\n",
    "Implemente a soma de Cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cauchy_n(f,a,b,n=100):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de erro\n",
    "\n",
    "O reflexo básico de toda esta seção será analisar como o erro $S_n - I$ tende a zero quando $n \\to \\infty$,\n",
    "ou, o que é o mesmo, quando $h \\to 0$.\n",
    "\n",
    "### Decomposição\n",
    "\n",
    "A primeira observação quanto ao erro é que este pode ser considerado uma _soma_ de $n$ erros diferentes.\n",
    "Isso porque, da aditividade da integral, temos:\n",
    "$$\\int_a^b f(x) \\, dx = \\sum_{k=0}^{n-1} \\left( \\int_{a + k h}^{a + kh + h} f(x) \\, dx \\right)\n",
    "                      = \\sum_{k=0}^{n-1} I _ {n,k}$$\n",
    "mantendo a mesma notação para $h$, e introduzindo as integrais $I _ {n,k}$ em cada intervalo.\n",
    "\n",
    "Para simplificar a notação futura, chamaremos $c_k = a + kh$ a extremidade esquerda de cada intervalo da partição,\n",
    "e $d_k = a + kh + h$ a extremidade direita.\n",
    "\n",
    "Assim, o _erro_ da estimativa da integral será:\n",
    "$$S_n - I = \\sum_k \\left(f(x_k)\\cdot h - I _ {n,k}\\right) = \\sum_k e _ {n,k}. $$\n",
    "Obviamente, alguns erros podem ocorrer por excesso, e outros por falta,\n",
    "mas devemos nos previnir - matematicamente - para a pior conspiração possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro de um termo\n",
    "\n",
    "Como $f$ é contínua, temos que o valor de $f(x)$ não varia muito dentro de um dado intervalo.\n",
    "Mais ainda, conforme este intervalo diminui, menor será a variação de $f(x)$.\n",
    "Chamamos a diferença entre o mínimo e o máximo de $f$ num intervalo $[x,y]$ de _oscilação_ de $f$ no intervalo,\n",
    "muitas vezes denotada $\\omega(f;x,y)$.\n",
    "\n",
    "Lembre, além disso, que a integral é uma \"área\", e portanto conforme $h$ diminui,\n",
    "também diminui o intervalo de integração, e com ele o valor da integral $I _ {n,k}$.\n",
    "Portanto, o erro diminui por duas razões quando $h \\to 0$: primeiramente,\n",
    "porque a função oscila menos num intervalo menor,\n",
    "segundo, porque a própria integral diminui de magnitude.\n",
    "\n",
    "Como já estamos treinados para pensar em erros relativos,\n",
    "percebemos que a diminuição importante do erro na integral\n",
    "vem da menor oscilação, e não da \"simples\" redução do intervalo de integração.\n",
    "Se a oscilação não diminuir, teremos um erro relativo essencialmente igual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma mudança de variáveis\n",
    "\n",
    "Ao aplicamos uma mudança de variáveis sobre a integral $I _ {n,k}$,\n",
    "de modo que o intervalo de integração não dependa mais de $h$,\n",
    "obtemos uma fórmula mais simples para o erro\n",
    "(absoluto, ainda: como vamos somar todos para obter o \"erro total\",\n",
    "é mais simples trabalhar com erros absolutos).\n",
    "Primeiro, a integral:\n",
    "$$I _ {n,k} = \\int_{c_k}^{d_k = c_k + h} f(x)\\,dx\n",
    "            = \\int_0^1 f \\big( c_k + th \\big) \\cdot h \\, dt\n",
    "            = h \\int_0^1 f \\big( c_k + th \\big)  \\, dt.$$\n",
    "E agora, o erro:\n",
    "$$e _ {n,k} = f(x_k) \\cdot h - I _ {n,k} = h \\int_0^1 \\big( f(x_k) - f(c_k + th) \\big) \\, dt.$$\n",
    "\n",
    "Podemos, daí, retirar uma estimativa do erro:\n",
    "$$\n",
    "e _ {n,k}\n",
    "   \\leq h \\int_0^1 \\bigl| f(x_k) - f(c_k + th) \\bigr| \\, dt\n",
    "   \\leq h \\int_0^1 \\omega(f; c_k, d_k) \\, dt\n",
    "   =    h \\cdot \\omega(f; c_k, d_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro total\n",
    "\n",
    "Como vimos anteriormente, o erro é a soma dos erros de cada termo,\n",
    "e poderia ocorrer que todos eles estivessem na mesma direção.\n",
    "Por isso, no pior dos casos, temos que\n",
    "$$\n",
    "\\left|S_n - I\\right|\n",
    "   \\leq \\sum_{k=0}^{n-1} e _ {n,k}\n",
    "   \\leq \\sum_{k=0}^{n-1} h \\cdot \\omega(f; c_k, d_k).\n",
    "$$\n",
    "\n",
    "Como $f$ é contínua, quando $h \\to 0$, cada um dos $\\omega(f; c_k, d_k)$ diminui,\n",
    "e vamos, na verdade, estimar ainda mais grosseiramente: usaremos $\\omega(f;h)$,\n",
    "que é a máxima variação de $f$ num intervalo (qualquer!!) de comprimento $h$.\n",
    "Assim, temos, para nossa estimativa:\n",
    "$$\\left|S_n - I\\right| \\leq h \\cdot \\sum_{k=0}^{n-1} \\omega(f;h) = nh \\cdot \\omega(f;h).$$\n",
    "Ora, da definição de $h$ temos que $b - a = nh$, logo:\n",
    "$$\\textstyle E_n \\leq (b-a) \\cdot \\omega\\left(f; \\frac{b-a}{n} \\right). $$\n",
    "\n",
    "Nesta fórmula, vemos bem que a importância de $n\\to \\infty$ (ou, equivalentemente, $h \\to 0$)\n",
    "reside na redução da oscilação da função, nos pequenos intervalos de discretização.\n",
    "Além disso, como só usamos a _continuidade_ de $f$,\n",
    "esta estimativa vale qualquer que seja o método de escolha dos pontos $x_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiência do erro\n",
    "\n",
    "### Exercício:\n",
    "Faça um gráfico do erro de integração de $f(x) = \\sin(x)$ no intervalo $[0,\\pi]$, em função do número de pontos utilizados.\n",
    "Como você faria para estimar o erro ao integrar $\\exp(-x^2)$ no intervalo $[0,1]$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return sin(x)\n",
    "def g(x): return exp(-x**2)\n",
    "\n",
    "# Continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diminuindo o erro: a fórmula do valor médio e a fórmula dos trapézios\n",
    "\n",
    "Vimos que o erro ao considerar somas de Riemann (na verdade, deveríamos chamar de \"somas de Cauchy\" estas que usam o ponto inicial)\n",
    "tende a zero porque a oscilação da função diminui conforme o tamanho do intervalo considerado diminui.\n",
    "Será que é possível (analogamente às diferenças centrais) obter fórmulas que convirjam mais rápido?\n",
    "Em geral (ou seja, para funções apenas contínuas) isso não é possível,\n",
    "pois a oscilação $\\omega$ é o único mecanismo de controle que possuímos.\n",
    "Mas, seguindo o princípio geral do curso, \"mais derivadas = melhor convergência\",\n",
    "vamos procurar métodos que nos dêem erros menores se supusermos que a função seja derivável.\n",
    "\n",
    "Começemos com funções uma vez deriváveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erro, com derivadas\n",
    "\n",
    "A primeira coisa a ser feita é estimar o erro da fórmula que já temos, supondo que $f$ seja derivável.\n",
    "Começamos com as somas de Cauchy, onde $x_k = c_k$:\n",
    "$$\\begin{align*}\n",
    "e _ {n,k} & = h \\cdot \\left| f(c_k) - \\int_0^1 f(c_k + th) \\, dt \\right|\n",
    "   = h \\cdot \\left| f(c_k) - \\int_0^1 \\big[ f(c_k) +  f'(\\xi) th \\big] \\, dt \\right|\n",
    "   = h \\cdot \\left| \\int_0^1 f'(\\xi) th \\, dt \\right| \\\\\n",
    "   & \\leq h^2 \\cdot \\int_0^1 \\max \\bigl| f'(\\xi) \\bigr| t \\, dt\n",
    "   = h^2 \\cdot \\max \\bigl| f'(\\xi) \\bigr| \\cdot \\frac{1}{2}\n",
    "\\end{align*}$$\n",
    "\n",
    "Ao somar todos os $e _ {n,k}$, teremos então que o erro $E_n$ será, no máximo,\n",
    "$$\n",
    "\\def\\maxhalf{\\frac{\\max \\bigl| f'(\\xi) \\bigr|}{2}}\n",
    "E_n\n",
    "  \\leq \\sum_{k=0}^{n-1} e _ {n,k}\n",
    "  \\leq n \\cdot h^2 \\maxhalf\n",
    "  \\leq h \\cdot (b - a) \\maxhalf.\n",
    "$$\n",
    "Assim, o erro da \"fórmula de Cauchy\" decresce linearmente com $h$.\n",
    "\n",
    "Obs: esta melhor estimativa decorre (mais abstratamente) da seguinte relação:\n",
    "a oscilação de $f$ num intervalo é sempre menor do que o máximo (do valor absoluto) da derivada $f'$ neste mesmo intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como diminuir o erro?\n",
    "\n",
    "Para reduzir o erro, podemos apostar em duas vertentes.\n",
    "Ou fazemos os erros $e _ {n,k}$ se compensarem, ou reduzimos os $e _ {n,k}$ diretamente.\n",
    "A primeira estratégia depende muito da função considerada, então vamos tentar arrumar um outro método.\n",
    "Em suma, gostaríamos de reduzir o erro\n",
    "$$\\big(\\text{Estimativa de $f$ no intervalo $[c_k, d_k]$}\\big) - \\int_0^1 f(c_k + th) \\, dt.$$\n",
    "\n",
    "Inspirados pela fórmula das diferenças centrais, podemos pensar que, se calcularmos $f$ no meio do intervalo,\n",
    "em vez de no bordo, o erro pode ser menor.\n",
    "Ou seja, usaremos $f(\\frac{c_k + d_k}{2})$ em vez de $f(c_k)$ como estimativa de $f$.\n",
    "Assim, em vez de calcularmos $S_n$, calcularemos\n",
    "$$M_n = \\sum_{k=0}^{n-1} f \\left(\\frac{c_k + d_k}{2} \\right) \\cdot h.$$\n",
    "Esta fórmula é conhecida como **fórmula do ponto médio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício:\n",
    "Supondo que $f$ seja **duas** vezes diferenciável, estime o erro cometido pela fórmula do ponto médio.\n",
    "\n",
    "Refaça os gráficos para as funções seno e gaussiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A regra do trapézio\n",
    "\n",
    "Outra idéia (também com cara de \"simetria\") para reduzir o erro é usar ambos pontos extremos em cada intervalo.\n",
    "A \"estimativa para $f$\" será a média de $f$ em cada um destes pontos, o que dá\n",
    "$$T_n\n",
    "  = \\sum_{k=0}^{n-1} \\left(\\frac{f(c_k) + f(d_k)}{2}\\right) \\cdot h\n",
    "  = \\frac{f(a) + f(b)}{2} \\cdot h + \\sum_{k=1}^{n-1} f(c_k) \\cdot h.$$\n",
    "\n",
    "Desta forma, o erro $e _ {n,k}$ será\n",
    "$$\\begin{align*}\n",
    "e _ {n,k} & = h \\cdot \\left(\\frac{f(c_k) + f(d_k)}{2} - \\int_0^1 f(c_k + th) \\, dt \\right) \\\\\n",
    "   & = h \\cdot \\left(\\frac{f(c_k) + f(c_k) + \\int_{c_k}^{d_k} f'(x) \\, dx}{2} - \\int_0^1 f(c_k) + \\int_0^{th} f'(c_k + u) \\, du \\, dt \\right) \\\\\n",
    "   & = h \\cdot \\left(\\frac{\\int_0^h f'(c_k + u) \\, du}{2} - \\int_0^1 \\int_0^{th} f'(c_k + u) \\, du \\, dt \\right) \\\\\n",
    "   & = h \\cdot \\left(\\int_0^h \\frac{f'(c_k + u)}{2} \\, dx - \\int_0^h f'(c_k + u) \\left(\\int_{u/h}^1 dt\\right) \\, du \\right) \\\\\n",
    "   & = h \\cdot \\left(\\int_0^h f'(c_k + u) \\left(\\frac{1}{2} - \\left(1 - \\frac{u}{h}\\right) \\right) \\, du \\right) \\\\\n",
    "   & = h \\cdot \\left(\\int_0^h f'(c_k + u) \\left(\\frac{u}{h} - \\frac{1}{2} \\right) \\, du \\right)\n",
    "       \\qquad \\text{e substituindo $v = \\left(\\frac{u}{h} - \\frac{1}{2} \\right)$:} \\\\\n",
    "   & = h \\cdot \\left(\\int_{-1/2}^{1/2} f'(m_k + hv) v \\cdot h \\, dv \\right) \\\\\n",
    "   & = h^2 \\cdot \\left(\\int_{-1/2}^{1/2} \\left( f'(m_k) + f''(\\xi) hv \\right) v \\, dv \\right) \\\\\n",
    "   & = h^3 \\cdot \\left(\\int_{-1/2}^{1/2} f''(\\xi) v^2 \\, dv \\right) \\\\\n",
    "   & = h^3 \\frac{f''(\\zeta)}{12}\n",
    "\\end{align*}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3.4",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
